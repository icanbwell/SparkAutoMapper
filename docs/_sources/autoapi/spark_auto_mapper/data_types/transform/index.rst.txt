:mod:`spark_auto_mapper.data_types.transform`
=============================================

.. py:module:: spark_auto_mapper.data_types.transform


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   spark_auto_mapper.data_types.transform.AutoMapperTransformDataType



.. data:: _TAutoMapperDataType
   

   

.. class:: AutoMapperTransformDataType(column: Union[(spark_auto_mapper.data_types.data_type_base.AutoMapperDataTypeBase, spark_auto_mapper.type_definitions.wrapper_types.AutoMapperColumnOrColumnLikeType)], value: _TAutoMapperDataType)


   Bases: :class:`spark_auto_mapper.data_types.array_base.AutoMapperArrayLikeBase`, :class:`Generic[_TAutoMapperDataType]`

   Abstract base class for generic types.

   A generic type is typically declared by inheriting from
   this class parameterized with one or more type variables.
   For example, a generic mapping type might be defined as::

     class Mapping(Generic[KT, VT]):
         def __getitem__(self, key: KT) -> VT:
             ...
         # Etc.

   This class can then be used as follows::

     def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:
         try:
             return mapping[key]
         except KeyError:
             return default

   .. method:: include_null_properties(self, include_null_properties: bool) -> None


   .. method:: get_column_spec(self, source_df: Optional[pyspark.sql.DataFrame], current_column: Optional[pyspark.sql.Column]) -> pyspark.sql.Column

      Gets the column spec for this automapper data type

      :param source_df: source data frame in case the automapper type needs that data to decide what to do
      :param current_column: (Optional) this is set when we are inside an array



